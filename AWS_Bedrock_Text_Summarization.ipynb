{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5HdV-yvIty2"
      },
      "outputs": [],
      "source": [
        "!pip install boto3 langchain pypdf unstructured[pdf] langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sqr0kkWTAaa"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
        "import json\n",
        "import boto3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehFtAxHGUy6j"
      },
      "outputs": [],
      "source": [
        "boto3_bedrock = boto3.client('bedrock-runtime',region_name='us-east-1',aws_access_key_id='{}',aws_secret_access_key='{}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXLmd31WUfvZ"
      },
      "outputs": [],
      "source": [
        "def summarizer(prompt_data):\n",
        "  inputText=prompt_data\n",
        "  body_part=json.dumps({'inputText': inputText,\n",
        "  'textGenerationConfig': {'maxTokenCount': 8192,\n",
        "  'stopSequences': [],\n",
        "  'temperature': 0,\n",
        "  'topP': 1}})\n",
        "  response = boto3_bedrock.invoke_model(\n",
        "  body=body_part,\n",
        "  contentType=\"application/json\",\n",
        "  accept=\"application/json\",\n",
        "  modelId='amazon.titan-text-express-v1'\n",
        "  )\n",
        "  output_text=json.loads(response['body'].read())['results'][0]['outputText']\n",
        "  return output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJgKzeNvSiSj"
      },
      "outputs": [],
      "source": [
        "def read_pdf_and_split(filename):\n",
        "  loader = UnstructuredPDFLoader(filename)\n",
        "  data = loader.load()\n",
        "  print(data)\n",
        "  splitter = RecursiveCharacterTextSplitter(\n",
        "  chunk_size=1000,\n",
        "  chunk_overlap=100,\n",
        "  length_function=len,\n",
        "  add_start_index=True\n",
        "  )\n",
        "  splitted_text = splitter.split_documents(data)\n",
        "\n",
        "  return splitted_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kbw4ars1UBFI"
      },
      "outputs": [],
      "source": [
        "pdf_document = read_pdf_and_split('/content/YOGI_2_0.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_document"
      ],
      "metadata": {
        "id": "1Ygmv_JZQZh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n10KYlgRU27h"
      },
      "outputs": [],
      "source": [
        "len(pdf_document)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47e8ZSV4YEwe"
      },
      "outputs": [],
      "source": [
        "summary= \"\"\n",
        "for i in pdf_document:\n",
        "  # gathering the text content of that specific chunk\n",
        "  chunk_content = i.page_content\n",
        "  # creating the prompt that will be passed into Bedrock with the text content of the chunk\n",
        "  prompt = f\"\"\"Human: Provide a detailed summary for the chunk of text provided to you:\n",
        "  Text: {chunk_content}\"\"\"\n",
        "  # passing the prompt into the summarizer function to generate the summary of that chunk, and appending it to\n",
        "  # the summary string\n",
        "  summary += summarizer(prompt)\n",
        "\n",
        "final_summary_prompt = f\"\"\"Human: You will be given a set of summaries from a document. Create a cohesive\n",
        "summary from the provided individual summaries. The summary should very detailed.\n",
        "Summaries: {summary}\"\"\"\n",
        "# generating the final summary of all the summaries we have previously generated.\n",
        "print(summarizer(final_summary_prompt))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlKIthr1rY+Vrj0gHzReFL"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}