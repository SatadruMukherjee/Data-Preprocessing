{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNxklpuhnkr1peRugh7b4Lu"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**DeeQu**, an open source data quality library, addresses data quality monitoring requirements and\n",
        "can scale to large datasets. DeeQu is built on top of Apache Spark to define \"**unit test for data**\"\n",
        "\n",
        "With DeeQu, you can populate data quality metrics and define data quality rules easily\n",
        "\n",
        "[**Current supported functionalities**](https://github.com/awslabs/python-deequ/blob/master/docs/checks.md)\n",
        "\n",
        "[**Documentation**](https://pydeequ.readthedocs.io/_/downloads/en/latest/pdf/)"
      ],
      "metadata": {
        "id": "pRUK6Yeha5K6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "41oL-UT50h6H"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qA2sZ7upOYc",
        "outputId": "2a0ab192-f11e-4f3e-bd12-dffa1d28c4cd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop2.7\""
      ],
      "metadata": {
        "id": "UYvzENiz0kxP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "ROZxulaX0mYh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydeequ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Its20kGh0nqq",
        "outputId": "4382916d-f475-434f-960b-5307d8c2dce2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydeequ\n",
            "  Downloading pydeequ-1.4.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from pydeequ) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from pydeequ) (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.0->pydeequ) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.0->pydeequ) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.0->pydeequ) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=0.23.0->pydeequ) (1.16.0)\n",
            "Installing collected packages: pydeequ\n",
            "Successfully installed pydeequ-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark==3.1.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUXQl_ig4j3g",
        "outputId": "a6a2a9b8-1020-425d-b32b-1ccfec234ef9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark==3.1.1\n",
            "  Downloading pyspark-3.1.1.tar.gz (212.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.3/212.3 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9 (from pyspark==3.1.1)\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.6/198.6 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767581 sha256=3b61f490bc9a30cc834e391a8ac1b018af5fe13c10268317a8d9d39089f346ef\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/3f/72/8efd988f9ae041f051c75e6834cd92dd6d13a726e206e8b6f3\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "  Attempting uninstall: py4j\n",
            "    Found existing installation: py4j 0.10.9.7\n",
            "    Uninstalling py4j-0.10.9.7:\n",
            "      Successfully uninstalled py4j-0.10.9.7\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['SPARK_VERSION'] = '3.1.1'"
      ],
      "metadata": {
        "id": "TNlL5vgx18m8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession, Row\n",
        "import pydeequ\n",
        "spark = (SparkSession\n",
        "             .builder\n",
        "             .config(\"spark.jars.packages\", pydeequ.deequ_maven_coord)\n",
        "             .config(\"spark.jars.excludes\", pydeequ.f2j_maven_coord)\n",
        "             .getOrCreate())"
      ],
      "metadata": {
        "id": "pz8u88K41URJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.sparkContext.parallelize([\n",
        "    Row(a=\"foo\", b=1, c=5, d=10, e=None, f=0),\n",
        "    Row(a=\"bar\", b=2, c=6, d=4, e= 12, f=90),\n",
        "    Row(a=\"baz\", b=3, c=None, d=None, e = 20, f= -10),\n",
        "    Row(a=\"cab\", b=3, c=8,  d=None, e =None, f=50)]).toDF()"
      ],
      "metadata": {
        "id": "JYpa7DdZ1XUv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiCesyjr2uzZ",
        "outputId": "3c31b809-3870-4f5a-cbef-82c697e1bd91"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+----+----+----+---+\n",
            "|  a|  b|   c|   d|   e|  f|\n",
            "+---+---+----+----+----+---+\n",
            "|foo|  1|   5|  10|null|  0|\n",
            "|bar|  2|   6|   4|  12| 90|\n",
            "|baz|  3|null|null|  20|-10|\n",
            "|cab|  3|   8|null|null| 50|\n",
            "+---+---+----+----+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")"
      ],
      "metadata": {
        "id": "RfTYjyBY2wNE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Size Validation**"
      ],
      "metadata": {
        "id": "WyQAj6BI6scf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**hasSize**(assertion, hint=None)--\n",
        "\n",
        "Creates a constraint that calculates the data frame size (number of rows) and runs the assertion(lambda) on it"
      ],
      "metadata": {
        "id": "45spUz3f7kyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.hasSize(lambda x: x == 4).hasSize(lambda x:x<=2))\\\n",
        " .run()"
      ],
      "metadata": {
        "id": "VpztRiGx5DhE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7341a8e9-b19d-48e4-898f-fce49dd037dd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python Callback server started!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlHBdN0S50PM",
        "outputId": "2919b795-847e-40d4-c3a2-6b80c39dd326"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+--------------------------+-----------------+--------------------------------------------------+\n",
            "|check      |check_level|check_status|constraint                |constraint_status|constraint_message                                |\n",
            "+-----------+-----------+------------+--------------------------+-----------------+--------------------------------------------------+\n",
            "|Basic Check|Warning    |Warning     |SizeConstraint(Size(None))|Success          |                                                  |\n",
            "|Basic Check|Warning    |Warning     |SizeConstraint(Size(None))|Failure          |Value: 4 does not meet the constraint requirement!|\n",
            "+-----------+-----------+------------+--------------------------+-----------------+--------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.hasSize(lambda x: x == 5))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EQvsj0X6_JE",
        "outputId": "87f0f0c5-b35b-432b-b9f3-be8000bf949f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+--------------------------+-----------------+--------------------------------------------------+\n",
            "|check      |check_level|check_status|constraint                |constraint_status|constraint_message                                |\n",
            "+-----------+-----------+------------+--------------------------+-----------------+--------------------------------------------------+\n",
            "|Basic Check|Warning    |Warning     |SizeConstraint(Size(None))|Failure          |Value: 4 does not meet the constraint requirement!|\n",
            "+-----------+-----------+------------+--------------------------+-----------------+--------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Completeness Validation**"
      ],
      "metadata": {
        "id": "yvp4bgJk76i2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**isComplete**(column, hint=None)--\n",
        "\n",
        "Creates a constraint that asserts on a column completion."
      ],
      "metadata": {
        "id": "VPI-lujl7yuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjGsSwzr86RD",
        "outputId": "d41a82f0-9342-46c7-eb63-8fabff2a4e9d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+----+----+----+---+\n",
            "|  a|  b|   c|   d|   e|  f|\n",
            "+---+---+----+----+----+---+\n",
            "|foo|  1|   5|  10|null|  0|\n",
            "|bar|  2|   6|   4|  12| 90|\n",
            "|baz|  3|null|null|  20|-10|\n",
            "|cab|  3|   8|null|null| 50|\n",
            "+---+---+----+----+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.isComplete('a'))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8cMi0Wi7UG0",
        "outputId": "e0965d19-2f71-48e2-d78e-b6676cc34cc6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+-------------------------------------------------+-----------------+------------------+\n",
            "|check      |check_level|check_status|constraint                                       |constraint_status|constraint_message|\n",
            "+-----------+-----------+------------+-------------------------------------------------+-----------------+------------------+\n",
            "|Basic Check|Warning    |Success     |CompletenessConstraint(Completeness(a,None,None))|Success          |                  |\n",
            "+-----------+-----------+------------+-------------------------------------------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBkA4H1SSEwi",
        "outputId": "9d9b92e2-ab09-4421-f71f-a8e2b3b7ded1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+----+----+----+---+\n",
            "|  a|  b|   c|   d|   e|  f|\n",
            "+---+---+----+----+----+---+\n",
            "|foo|  1|   5|  10|null|  0|\n",
            "|bar|  2|   6|   4|  12| 90|\n",
            "|baz|  3|null|null|  20|-10|\n",
            "|cab|  3|   8|null|null| 50|\n",
            "+---+---+----+----+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.isComplete('c'))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_HpcVfA8vvO",
        "outputId": "401228c1-aa89-44f1-9f27-575ccbf2a307"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+-------------------------------------------------+-----------------+-----------------------------------------------------+\n",
            "|check      |check_level|check_status|constraint                                       |constraint_status|constraint_message                                   |\n",
            "+-----------+-----------+------------+-------------------------------------------------+-----------------+-----------------------------------------------------+\n",
            "|Basic Check|Warning    |Warning     |CompletenessConstraint(Completeness(c,None,None))|Failure          |Value: 0.75 does not meet the constraint requirement!|\n",
            "+-----------+-----------+------------+-------------------------------------------------+-----------------+-----------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxC5OYnMSHpi",
        "outputId": "c4b949e5-8f5d-40fb-e608-4a89df0ee827"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+----+----+----+---+\n",
            "|  a|  b|   c|   d|   e|  f|\n",
            "+---+---+----+----+----+---+\n",
            "|foo|  1|   5|  10|null|  0|\n",
            "|bar|  2|   6|   4|  12| 90|\n",
            "|baz|  3|null|null|  20|-10|\n",
            "|cab|  3|   8|null|null| 50|\n",
            "+---+---+----+----+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.isComplete('d'))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agpz-qoSRcPU",
        "outputId": "f0ff6cac-0a4a-4e61-a071-42d2099673ad"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+-------------------------------------------------+-----------------+----------------------------------------------------+\n",
            "|check      |check_level|check_status|constraint                                       |constraint_status|constraint_message                                  |\n",
            "+-----------+-----------+------------+-------------------------------------------------+-----------------+----------------------------------------------------+\n",
            "|Basic Check|Warning    |Warning     |CompletenessConstraint(Completeness(d,None,None))|Failure          |Value: 0.5 does not meet the constraint requirement!|\n",
            "+-----------+-----------+------------+-------------------------------------------------+-----------------+----------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**areComplete**(column, hint=None)--\n",
        "\n",
        "Creates a constraint that asserts completion in combined set of columns."
      ],
      "metadata": {
        "id": "YZoU7PlhRjWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cn7F6cKmSJsO",
        "outputId": "6ee3ea79-a833-4c3f-98d5-f1e2b684bbdb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+----+----+----+---+\n",
            "|  a|  b|   c|   d|   e|  f|\n",
            "+---+---+----+----+----+---+\n",
            "|foo|  1|   5|  10|null|  0|\n",
            "|bar|  2|   6|   4|  12| 90|\n",
            "|baz|  3|null|null|  20|-10|\n",
            "|cab|  3|   8|null|null| 50|\n",
            "+---+---+----+----+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.areComplete(['a','b']))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WopcUiMpc7T",
        "outputId": "d2b8d633-f641-43e2-af3b-7a635c9c8ddb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+------------------------------------------------------------------------------------------------------------------+-----------------+------------------+\n",
            "|check      |check_level|check_status|constraint                                                                                                        |constraint_status|constraint_message|\n",
            "+-----------+-----------+------------+------------------------------------------------------------------------------------------------------------------+-----------------+------------------+\n",
            "|Basic Check|Warning    |Success     |ComplianceConstraint(Compliance(Combined Completeness,((a IS NOT NULL) AND (b IS NOT NULL)),None,List(a, b),None))|Success          |                  |\n",
            "+-----------+-----------+------------+------------------------------------------------------------------------------------------------------------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbBT2TIESMHK",
        "outputId": "9bff2ea6-0b55-4689-9bce-e0c91efe9e81"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+----+----+----+---+\n",
            "|  a|  b|   c|   d|   e|  f|\n",
            "+---+---+----+----+----+---+\n",
            "|foo|  1|   5|  10|null|  0|\n",
            "|bar|  2|   6|   4|  12| 90|\n",
            "|baz|  3|null|null|  20|-10|\n",
            "|cab|  3|   8|null|null| 50|\n",
            "+---+---+----+----+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.areComplete(['a','c']))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AK-dzqTpikV",
        "outputId": "5b2a576e-9415-4a78-f8fa-024cd2465724"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+------------------------------------------------------------------------------------------------------------------+-----------------+-----------------------------------------------------+\n",
            "|check      |check_level|check_status|constraint                                                                                                        |constraint_status|constraint_message                                   |\n",
            "+-----------+-----------+------------+------------------------------------------------------------------------------------------------------------------+-----------------+-----------------------------------------------------+\n",
            "|Basic Check|Warning    |Warning     |ComplianceConstraint(Compliance(Combined Completeness,((a IS NOT NULL) AND (c IS NOT NULL)),None,List(a, c),None))|Failure          |Value: 0.75 does not meet the constraint requirement!|\n",
            "+-----------+-----------+------------+------------------------------------------------------------------------------------------------------------------+-----------------+-----------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70s90KPRSTT1",
        "outputId": "0df95e4c-994e-40ca-9c9f-14cc45d6d241"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+----+----+----+---+\n",
            "|  a|  b|   c|   d|   e|  f|\n",
            "+---+---+----+----+----+---+\n",
            "|foo|  1|   5|  10|null|  0|\n",
            "|bar|  2|   6|   4|  12| 90|\n",
            "|baz|  3|null|null|  20|-10|\n",
            "|cab|  3|   8|null|null| 50|\n",
            "+---+---+----+----+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.areComplete(['a','d']))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDfAm-IMtdAJ",
        "outputId": "16df3251-0b8a-48bf-88ac-4ab2373566a2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+------------------------------------------------------------------------------------------------------------------+-----------------+----------------------------------------------------+\n",
            "|check      |check_level|check_status|constraint                                                                                                        |constraint_status|constraint_message                                  |\n",
            "+-----------+-----------+------------+------------------------------------------------------------------------------------------------------------------+-----------------+----------------------------------------------------+\n",
            "|Basic Check|Warning    |Warning     |ComplianceConstraint(Compliance(Combined Completeness,((a IS NOT NULL) AND (d IS NOT NULL)),None,List(a, d),None))|Failure          |Value: 0.5 does not meet the constraint requirement!|\n",
            "+-----------+-----------+------------+------------------------------------------------------------------------------------------------------------------+-----------------+----------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**hasCompleteness**(column, hint=None)--\n",
        "\n",
        "Creates a constraint that asserts column completion."
      ],
      "metadata": {
        "id": "bjFa_5vySz8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cw2pHeYmTQTO",
        "outputId": "157be3b5-63c7-4298-b315-eb83c5670ab0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+----+----+----+---+\n",
            "|  a|  b|   c|   d|   e|  f|\n",
            "+---+---+----+----+----+---+\n",
            "|foo|  1|   5|  10|null|  0|\n",
            "|bar|  2|   6|   4|  12| 90|\n",
            "|baz|  3|null|null|  20|-10|\n",
            "|cab|  3|   8|null|null| 50|\n",
            "+---+---+----+----+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.hasCompleteness('a',lambda x: x >= 0.8))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IcDCNePp5KV",
        "outputId": "aea65d0f-f7f1-4bb8-bb55-1b4f665ff9d6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+-------------------------------------------------+-----------------+------------------+\n",
            "|check      |check_level|check_status|constraint                                       |constraint_status|constraint_message|\n",
            "+-----------+-----------+------------+-------------------------------------------------+-----------------+------------------+\n",
            "|Basic Check|Warning    |Success     |CompletenessConstraint(Completeness(a,None,None))|Success          |                  |\n",
            "+-----------+-----------+------------+-------------------------------------------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3vLlxp6TSgg",
        "outputId": "0e87b87f-5a00-41e8-a939-06a91b19bc40"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+----+----+----+---+\n",
            "|  a|  b|   c|   d|   e|  f|\n",
            "+---+---+----+----+----+---+\n",
            "|foo|  1|   5|  10|null|  0|\n",
            "|bar|  2|   6|   4|  12| 90|\n",
            "|baz|  3|null|null|  20|-10|\n",
            "|cab|  3|   8|null|null| 50|\n",
            "+---+---+----+----+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.hasCompleteness('c',lambda x: x >= 0.8))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NvV_ejPqIOZ",
        "outputId": "2a400ca3-bc78-4cdb-8929-f95998262950"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+-------------------------------------------------+-----------------+-----------------------------------------------------+\n",
            "|check      |check_level|check_status|constraint                                       |constraint_status|constraint_message                                   |\n",
            "+-----------+-----------+------------+-------------------------------------------------+-----------------+-----------------------------------------------------+\n",
            "|Basic Check|Warning    |Warning     |CompletenessConstraint(Completeness(c,None,None))|Failure          |Value: 0.75 does not meet the constraint requirement!|\n",
            "+-----------+-----------+------------+-------------------------------------------------+-----------------+-----------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtANnkOvTW32",
        "outputId": "603f0c94-5706-4893-8267-01b20b5c0935"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+----+----+----+---+\n",
            "|  a|  b|   c|   d|   e|  f|\n",
            "+---+---+----+----+----+---+\n",
            "|foo|  1|   5|  10|null|  0|\n",
            "|bar|  2|   6|   4|  12| 90|\n",
            "|baz|  3|null|null|  20|-10|\n",
            "|cab|  3|   8|null|null| 50|\n",
            "+---+---+----+----+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.hasCompleteness('d',lambda x: x >= 0.5))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jb8NwvN-TYXK",
        "outputId": "7212cb87-461a-4693-ffd9-ca36bd270115"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+-------------------------------------------------+-----------------+------------------+\n",
            "|check      |check_level|check_status|constraint                                       |constraint_status|constraint_message|\n",
            "+-----------+-----------+------------+-------------------------------------------------+-----------------+------------------+\n",
            "|Basic Check|Warning    |Success     |CompletenessConstraint(Completeness(d,None,None))|Success          |                  |\n",
            "+-----------+-----------+------------+-------------------------------------------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**areAnyComplete**(column, hint=None)--\n",
        "\n",
        "Creates a constraint that asserts any completion in the combined set of columns"
      ],
      "metadata": {
        "id": "wkehg6TUUYxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flkOz2KXTsvL",
        "outputId": "002770fd-c096-47e0-8583-75ae7e9c0a0f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+----+----+----+---+\n",
            "|  a|  b|   c|   d|   e|  f|\n",
            "+---+---+----+----+----+---+\n",
            "|foo|  1|   5|  10|null|  0|\n",
            "|bar|  2|   6|   4|  12| 90|\n",
            "|baz|  3|null|null|  20|-10|\n",
            "|cab|  3|   8|null|null| 50|\n",
            "+---+---+----+----+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.areAnyComplete(['a','d']))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7t9VkzkUSUl",
        "outputId": "c9b8c76b-766a-4283-8dac-ba4bd533bdde"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+------------------------------------------------------------------------------------------------------------+-----------------+------------------+\n",
            "|check      |check_level|check_status|constraint                                                                                                  |constraint_status|constraint_message|\n",
            "+-----------+-----------+------------+------------------------------------------------------------------------------------------------------------+-----------------+------------------+\n",
            "|Basic Check|Warning    |Success     |ComplianceConstraint(Compliance(Any Completeness,((a IS NOT NULL) OR (d IS NOT NULL)),None,List(a, d),None))|Success          |                  |\n",
            "+-----------+-----------+------------+------------------------------------------------------------------------------------------------------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCzt027EUy56",
        "outputId": "dc69b073-a19e-4335-c99f-4a1ed444f5d3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+----+----+----+---+\n",
            "|  a|  b|   c|   d|   e|  f|\n",
            "+---+---+----+----+----+---+\n",
            "|foo|  1|   5|  10|null|  0|\n",
            "|bar|  2|   6|   4|  12| 90|\n",
            "|baz|  3|null|null|  20|-10|\n",
            "|cab|  3|   8|null|null| 50|\n",
            "+---+---+----+----+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.areAnyComplete(['c','d','a']))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsdBobyTqQZb",
        "outputId": "7ce8a129-759d-4960-a509-8ab2ca811ee8"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+------------------------------------------------------------------------------------------------------------------------------------+-----------------+------------------+\n",
            "|check      |check_level|check_status|constraint                                                                                                                          |constraint_status|constraint_message|\n",
            "+-----------+-----------+------------+------------------------------------------------------------------------------------------------------------------------------------+-----------------+------------------+\n",
            "|Basic Check|Warning    |Success     |ComplianceConstraint(Compliance(Any Completeness,(((c IS NOT NULL) OR (d IS NOT NULL)) OR (a IS NOT NULL)),None,List(c, d, a),None))|Success          |                  |\n",
            "+-----------+-----------+------------+------------------------------------------------------------------------------------------------------------------------------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYW6KpP6WFmf",
        "outputId": "7add2883-0549-4840-8939-95cfd94e0819"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+----+----+----+---+\n",
            "|  a|  b|   c|   d|   e|  f|\n",
            "+---+---+----+----+----+---+\n",
            "|foo|  1|   5|  10|null|  0|\n",
            "|bar|  2|   6|   4|  12| 90|\n",
            "|baz|  3|null|null|  20|-10|\n",
            "|cab|  3|   8|null|null| 50|\n",
            "+---+---+----+----+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.areAnyComplete(['c','e']))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18dhaLeIVr4w",
        "outputId": "9db622e7-2891-45f4-d8b8-dd3daa7aade4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+------------------------------------------------------------------------------------------------------------+-----------------+------------------+\n",
            "|check      |check_level|check_status|constraint                                                                                                  |constraint_status|constraint_message|\n",
            "+-----------+-----------+------------+------------------------------------------------------------------------------------------------------------+-----------------+------------------+\n",
            "|Basic Check|Warning    |Success     |ComplianceConstraint(Compliance(Any Completeness,((c IS NOT NULL) OR (e IS NOT NULL)),None,List(c, e),None))|Success          |                  |\n",
            "+-----------+-----------+------------+------------------------------------------------------------------------------------------------------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Duplicates Validation**"
      ],
      "metadata": {
        "id": "p_wvN8JP88k5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**isUnique**(column, hint=None)--\n",
        "\n",
        "Creates a constraint that asserts on a column uniqueness\n"
      ],
      "metadata": {
        "id": "TVozRuc_9I-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDD6gq3F9m5A",
        "outputId": "dff1e126-7ba4-4d55-e0c7-445cbe29ef1a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+----+----+----+---+\n",
            "|  a|  b|   c|   d|   e|  f|\n",
            "+---+---+----+----+----+---+\n",
            "|foo|  1|   5|  10|null|  0|\n",
            "|bar|  2|   6|   4|  12| 90|\n",
            "|baz|  3|null|null|  20|-10|\n",
            "|cab|  3|   8|null|null| 50|\n",
            "+---+---+----+----+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.isUnique('a'))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUmQod0b9RCb",
        "outputId": "2d5b3dfa-e7fa-4738-e0e4-135927475c33"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+---------------------------------------------------+-----------------+------------------+\n",
            "|check      |check_level|check_status|constraint                                         |constraint_status|constraint_message|\n",
            "+-----------+-----------+------------+---------------------------------------------------+-----------------+------------------+\n",
            "|Basic Check|Warning    |Success     |UniquenessConstraint(Uniqueness(List(a),None,None))|Success          |                  |\n",
            "+-----------+-----------+------------+---------------------------------------------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eI69pKfxWOj-",
        "outputId": "4119989c-5c7c-4045-b76f-ae440f99d0a4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+----+----+----+---+\n",
            "|  a|  b|   c|   d|   e|  f|\n",
            "+---+---+----+----+----+---+\n",
            "|foo|  1|   5|  10|null|  0|\n",
            "|bar|  2|   6|   4|  12| 90|\n",
            "|baz|  3|null|null|  20|-10|\n",
            "|cab|  3|   8|null|null| 50|\n",
            "+---+---+----+----+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.isUnique('b'))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLFWjuWl9kfw",
        "outputId": "fd3ccb90-a2f7-42e3-9037-6c26957600ba"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+---------------------------------------------------+-----------------+----------------------------------------------------+\n",
            "|check      |check_level|check_status|constraint                                         |constraint_status|constraint_message                                  |\n",
            "+-----------+-----------+------------+---------------------------------------------------+-----------------+----------------------------------------------------+\n",
            "|Basic Check|Warning    |Warning     |UniquenessConstraint(Uniqueness(List(b),None,None))|Failure          |Value: 0.5 does not meet the constraint requirement!|\n",
            "+-----------+-----------+------------+---------------------------------------------------+-----------------+----------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORa2RdvLvRka",
        "outputId": "3894b45f-5d4b-4d91-a4b5-e52f9caba2b9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+----+----+----+---+\n",
            "|  a|  b|   c|   d|   e|  f|\n",
            "+---+---+----+----+----+---+\n",
            "|foo|  1|   5|  10|null|  0|\n",
            "|bar|  2|   6|   4|  12| 90|\n",
            "|baz|  3|null|null|  20|-10|\n",
            "|cab|  3|   8|null|null| 50|\n",
            "+---+---+----+----+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.isUnique('d'))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CF5z6weLWXnM",
        "outputId": "be65ca4b-3001-416c-d435-94e0ac95895a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+---------------------------------------------------+-----------------+------------------+\n",
            "|check      |check_level|check_status|constraint                                         |constraint_status|constraint_message|\n",
            "+-----------+-----------+------------+---------------------------------------------------+-----------------+------------------+\n",
            "|Basic Check|Warning    |Success     |UniquenessConstraint(Uniqueness(List(d),None,None))|Success          |                  |\n",
            "+-----------+-----------+------------+---------------------------------------------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**hasUniqueness**(column, hint=None)--\n",
        "\n",
        "Creates a constraint that asserts any uniqueness in a single or combined set of key columns.\n"
      ],
      "metadata": {
        "id": "A-2ow4CpWzcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vuVYqFiW8QX",
        "outputId": "4550541b-b4a4-46ee-9e13-cb5f4ec9981d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+----+----+----+---+\n",
            "|  a|  b|   c|   d|   e|  f|\n",
            "+---+---+----+----+----+---+\n",
            "|foo|  1|   5|  10|null|  0|\n",
            "|bar|  2|   6|   4|  12| 90|\n",
            "|baz|  3|null|null|  20|-10|\n",
            "|cab|  3|   8|null|null| 50|\n",
            "+---+---+----+----+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.hasUniqueness(['a'],lambda x : x > 0.75))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waLq3x3wXDEy",
        "outputId": "1cc92fdf-8c3e-459c-f576-f2754e18d7f2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python Callback server started!\n",
            "+-----------+-----------+------------+--------------------------------------------------------+-----------------+------------------+\n",
            "|check      |check_level|check_status|constraint                                              |constraint_status|constraint_message|\n",
            "+-----------+-----------+------------+--------------------------------------------------------+-----------------+------------------+\n",
            "|Basic Check|Warning    |Success     |UniquenessConstraint(Uniqueness(Stream(a, ?),None,None))|Success          |                  |\n",
            "+-----------+-----------+------------+--------------------------------------------------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3H1BA4dXFBn",
        "outputId": "4c60a33b-27a0-414e-f7d7-95a1c9ff1a27"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+----+----+----+---+\n",
            "|  a|  b|   c|   d|   e|  f|\n",
            "+---+---+----+----+----+---+\n",
            "|foo|  1|   5|  10|null|  0|\n",
            "|bar|  2|   6|   4|  12| 90|\n",
            "|baz|  3|null|null|  20|-10|\n",
            "|cab|  3|   8|null|null| 50|\n",
            "+---+---+----+----+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.hasUniqueness(['b'],lambda x : x > 0.75))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBSwgRGQuasP",
        "outputId": "1213f368-b9d6-47f6-9797-e98954892458"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+--------------------------------------------------------+-----------------+----------------------------------------------------+\n",
            "|check      |check_level|check_status|constraint                                              |constraint_status|constraint_message                                  |\n",
            "+-----------+-----------+------------+--------------------------------------------------------+-----------------+----------------------------------------------------+\n",
            "|Basic Check|Warning    |Warning     |UniquenessConstraint(Uniqueness(Stream(b, ?),None,None))|Failure          |Value: 0.5 does not meet the constraint requirement!|\n",
            "+-----------+-----------+------------+--------------------------------------------------------+-----------------+----------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**hasMin**(column, hint=None)--\n",
        "\n",
        "Creates a constraint that asserts on the minimum of a column.\n"
      ],
      "metadata": {
        "id": "moWuhvo4XTWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmK48-YewKM8",
        "outputId": "0d5fe430-6149-4749-aca0-55289f248ad6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+----+----+----+---+\n",
            "|  a|  b|   c|   d|   e|  f|\n",
            "+---+---+----+----+----+---+\n",
            "|foo|  1|   5|  10|null|  0|\n",
            "|bar|  2|   6|   4|  12| 90|\n",
            "|baz|  3|null|null|  20|-10|\n",
            "|cab|  3|   8|null|null| 50|\n",
            "+---+---+----+----+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.hasMin('b',lambda x : x <= 2))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Obw951vdwGap",
        "outputId": "462e1419-eca8-41f1-e653-dac725d3abe8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+---------------------------------------+-----------------+------------------+\n",
            "|check      |check_level|check_status|constraint                             |constraint_status|constraint_message|\n",
            "+-----------+-----------+------------+---------------------------------------+-----------------+------------------+\n",
            "|Basic Check|Warning    |Success     |MinimumConstraint(Minimum(b,None,None))|Success          |                  |\n",
            "+-----------+-----------+------------+---------------------------------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**hasMax**(column, hint=None)--\n",
        "\n",
        "Creates a constraint that asserts on the maximum of the column\n",
        "\n",
        "**hasMean**(column, assertion, hint=None)--\n",
        "\n",
        "Creates a constraint that asserts on the mean of the column\n",
        "\n",
        "**hasSum**(column, assertion, hint=None)--\n",
        "\n",
        "Creates a constraint that asserts on the sum of the column\n"
      ],
      "metadata": {
        "id": "6fyQ-6txXgkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcMYaEDKXvr3",
        "outputId": "e89dca2f-3bfa-4b19-f0bb-45987c47bbd7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+----+----+----+---+\n",
            "|  a|  b|   c|   d|   e|  f|\n",
            "+---+---+----+----+----+---+\n",
            "|foo|  1|   5|  10|null|  0|\n",
            "|bar|  2|   6|   4|  12| 90|\n",
            "|baz|  3|null|null|  20|-10|\n",
            "|cab|  3|   8|null|null| 50|\n",
            "+---+---+----+----+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.hasMin('b',lambda x : x == 1)\\\n",
        " .hasMax('c',lambda x : x == 9)\\\n",
        " .hasMean('d',lambda x : x == 2)\\\n",
        " .hasSum('b',lambda x : x == 9)) \\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAWq-RXHwaGR",
        "outputId": "5ab88acc-360e-479a-f224-3e43e57ad835"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+---------------------------------------+-----------------+----------------------------------------------------+\n",
            "|check      |check_level|check_status|constraint                             |constraint_status|constraint_message                                  |\n",
            "+-----------+-----------+------------+---------------------------------------+-----------------+----------------------------------------------------+\n",
            "|Basic Check|Warning    |Warning     |MinimumConstraint(Minimum(b,None,None))|Success          |                                                    |\n",
            "|Basic Check|Warning    |Warning     |MaximumConstraint(Maximum(c,None,None))|Failure          |Value: 8.0 does not meet the constraint requirement!|\n",
            "|Basic Check|Warning    |Warning     |MeanConstraint(Mean(d,None))           |Failure          |Value: 7.0 does not meet the constraint requirement!|\n",
            "|Basic Check|Warning    |Warning     |SumConstraint(Sum(b,None))             |Success          |                                                    |\n",
            "+-----------+-----------+------------+---------------------------------------+-----------------+----------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**isNonNegative**(column, assertion=None, hint=None)--\n",
        "\n",
        "Creates a constraint which asserts that a column contains no negative values.\n",
        "\n",
        "**isPositive**(column, assertion=None, hint=None)\n",
        "Creates a constraint which asserts that a column contains no negative values and is greater than 0."
      ],
      "metadata": {
        "id": "3RxnybhfdXp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = spark.sparkContext.parallelize([\n",
        "    Row(a=1, b=1),\n",
        "    Row(a=0, b=-2),\n",
        "    Row(a=2, b=3),\n",
        "    Row(a=3, b=3)]).toDF()\n",
        "df1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omG1Q7Ryd4mV",
        "outputId": "b58b6a0a-e487-47c0-ff7e-ac2916f9d099"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+\n",
            "|  a|  b|\n",
            "+---+---+\n",
            "|  1|  1|\n",
            "|  0| -2|\n",
            "|  2|  3|\n",
            "|  3|  3|\n",
            "+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df1) \\\n",
        " .addCheck(check.isPositive('a').isNonNegative('a').isPositive('b').isNonNegative('b')) \\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4q3G8I2xdfIR",
        "outputId": "087ded1f-09b4-4b1e-c15c-4edb3aeef01d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+-------------------------------------------------------------------------------------------------------------------+-----------------+-----------------------------------------------------+\n",
            "|check      |check_level|check_status|constraint                                                                                                         |constraint_status|constraint_message                                   |\n",
            "+-----------+-----------+------------+-------------------------------------------------------------------------------------------------------------------+-----------------+-----------------------------------------------------+\n",
            "|Basic Check|Warning    |Warning     |ComplianceConstraint(Compliance(a is positive,COALESCE(CAST(a AS DECIMAL(20,10)), 1.0) > 0,None,List(a),None))     |Failure          |Value: 0.75 does not meet the constraint requirement!|\n",
            "|Basic Check|Warning    |Warning     |ComplianceConstraint(Compliance(a is non-negative,COALESCE(CAST(a AS DECIMAL(20,10)), 0.0) >= 0,None,List(a),None))|Success          |                                                     |\n",
            "|Basic Check|Warning    |Warning     |ComplianceConstraint(Compliance(b is positive,COALESCE(CAST(b AS DECIMAL(20,10)), 1.0) > 0,None,List(b),None))     |Failure          |Value: 0.75 does not meet the constraint requirement!|\n",
            "|Basic Check|Warning    |Warning     |ComplianceConstraint(Compliance(b is non-negative,COALESCE(CAST(b AS DECIMAL(20,10)), 0.0) >= 0,None,List(b),None))|Failure          |Value: 0.75 does not meet the constraint requirement!|\n",
            "+-----------+-----------+------------+-------------------------------------------------------------------------------------------------------------------+-----------------+-----------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**isContainedIn**(column, allowed_values, assertion=None, hint=None)--\n",
        "\n",
        "Asserts that every non-null value in a column is contained in a set of predefined values\n",
        "\n"
      ],
      "metadata": {
        "id": "umeZjdgaYC56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zOsLNLsX7ym",
        "outputId": "ba4fd242-9a03-45ec-b57b-3fed594fbad0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+----+----+----+---+\n",
            "|  a|  b|   c|   d|   e|  f|\n",
            "+---+---+----+----+----+---+\n",
            "|foo|  1|   5|  10|null|  0|\n",
            "|bar|  2|   6|   4|  12| 90|\n",
            "|baz|  3|null|null|  20|-10|\n",
            "|cab|  3|   8|null|null| 50|\n",
            "+---+---+----+----+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.isContainedIn(\"a\", [\"foo\", \"bar\", \"baz\"]))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7Z90e27xQVZ",
        "outputId": "a3dbf0a9-b9b2-4972-ae62-5012d2ca8492"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+------------------------------------------------------------------------------------------------------------------------+-----------------+-----------------------------------------------------+\n",
            "|check      |check_level|check_status|constraint                                                                                                              |constraint_status|constraint_message                                   |\n",
            "+-----------+-----------+------------+------------------------------------------------------------------------------------------------------------------------+-----------------+-----------------------------------------------------+\n",
            "|Basic Check|Warning    |Warning     |ComplianceConstraint(Compliance(a contained in foo,bar,baz,`a` IS NULL OR `a` IN ('foo','bar','baz'),None,List(a),None))|Failure          |Value: 0.75 does not meet the constraint requirement!|\n",
            "+-----------+-----------+------------+------------------------------------------------------------------------------------------------------------------------+-----------------+-----------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-YvY3TjYPXE",
        "outputId": "7720ba47-ed48-4e00-ac30-885a5f4596fd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+----+----+----+---+\n",
            "|  a|  b|   c|   d|   e|  f|\n",
            "+---+---+----+----+----+---+\n",
            "|foo|  1|   5|  10|null|  0|\n",
            "|bar|  2|   6|   4|  12| 90|\n",
            "|baz|  3|null|null|  20|-10|\n",
            "|cab|  3|   8|null|null| 50|\n",
            "+---+---+----+----+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.isContainedIn(\"a\", [\"foo\", \"bar\", \"baz\", \"cab\"]))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sz6V_QVSYO0J",
        "outputId": "df0f04cd-2737-45a2-848e-81f482f74a1e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+----------------------------------------------------------------------------------------------------------------------------------+-----------------+------------------+\n",
            "|check      |check_level|check_status|constraint                                                                                                                        |constraint_status|constraint_message|\n",
            "+-----------+-----------+------------+----------------------------------------------------------------------------------------------------------------------------------+-----------------+------------------+\n",
            "|Basic Check|Warning    |Success     |ComplianceConstraint(Compliance(a contained in foo,bar,baz,cab,`a` IS NULL OR `a` IN ('foo','bar','baz','cab'),None,List(a),None))|Success          |                  |\n",
            "+-----------+-----------+------------+----------------------------------------------------------------------------------------------------------------------------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = spark.sparkContext.parallelize([\n",
        "    Row(a=\"foo\", b=1, c=5, d=10, e=None, f=0),\n",
        "    Row(a=\"bar\", b=2, c=6, d=4, e= 12, f=90),\n",
        "    Row(a=\"baz\", b=3, c=None, d=None, e = 20, f= -10),\n",
        "    Row(a=\"cab\", b=3, c=8,  d=None, e =None, f=50),\n",
        "    Row(a=None, b=3, c=8,  d=None, e =None, f=50)]).toDF()\n",
        "df2.show()"
      ],
      "metadata": {
        "id": "4ubDjY51uBXM",
        "outputId": "a0675d25-8247-4eb8-fc3b-effb705f101b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+----+----+----+---+\n",
            "|   a|  b|   c|   d|   e|  f|\n",
            "+----+---+----+----+----+---+\n",
            "| foo|  1|   5|  10|null|  0|\n",
            "| bar|  2|   6|   4|  12| 90|\n",
            "| baz|  3|null|null|  20|-10|\n",
            "| cab|  3|   8|null|null| 50|\n",
            "|null|  3|   8|null|null| 50|\n",
            "+----+---+----+----+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.isContainedIn(\"a\", [\"foo\", \"bar\", \"baz\", \"cab\"]))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "id": "_n_6tLwhuHKT",
        "outputId": "f133b71d-4fb8-4423-b9de-68b92f8bee72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+----------------------------------------------------------------------------------------------------------------------------------+-----------------+------------------+\n",
            "|check      |check_level|check_status|constraint                                                                                                                        |constraint_status|constraint_message|\n",
            "+-----------+-----------+------------+----------------------------------------------------------------------------------------------------------------------------------+-----------------+------------------+\n",
            "|Basic Check|Warning    |Success     |ComplianceConstraint(Compliance(a contained in foo,bar,baz,cab,`a` IS NULL OR `a` IN ('foo','bar','baz','cab'),None,List(a),None))|Success          |                  |\n",
            "+-----------+-----------+------------+----------------------------------------------------------------------------------------------------------------------------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**containsURL**(column, assertion=None, hint=None)--\n",
        "\n",
        "Verifies against a URL pattern\n",
        "\n"
      ],
      "metadata": {
        "id": "kwno5hgEC0jM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = spark.createDataFrame([\n",
        " (1, \"Product A\", \"awesome thing.\", \"high\", 2),\n",
        " (2, \"Product B\", \"available at http://producta.example.com\", None, 0),\n",
        " (3, None, None, \"medium\", 6),\n",
        " (4, \"Product D\", \"checkout https://productd.example.org\", \"low\", 10),\n",
        " (5, \"Product E\", None, \"high\", 18)],\n",
        "['id', 'productName', 'description', 'priority', 'numViews'])\n",
        "df3.show(truncate=False)"
      ],
      "metadata": {
        "id": "2l5UFPvICUP9",
        "outputId": "e0c36240-231a-4429-db4f-5ea640068fd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----------+----------------------------------------+--------+--------+\n",
            "|id |productName|description                             |priority|numViews|\n",
            "+---+-----------+----------------------------------------+--------+--------+\n",
            "|1  |Product A  |awesome thing.                          |high    |2       |\n",
            "|2  |Product B  |available at http://producta.example.com|null    |0       |\n",
            "|3  |null       |null                                    |medium  |6       |\n",
            "|4  |Product D  |checkout https://productd.example.org   |low     |10      |\n",
            "|5  |Product E  |null                                    |high    |18      |\n",
            "+---+-----------+----------------------------------------+--------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df3) \\\n",
        " .addCheck(check.containsURL(\"description\", lambda x: x >=0.3))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "id": "iVTwcgHmDWyv",
        "outputId": "eb674cbf-d190-4317-e956-ddb2c1310e15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+------------------------+-----------------+------------------+\n",
            "|check      |check_level|check_status|constraint              |constraint_status|constraint_message|\n",
            "+-----------+-----------+------------+------------------------+-----------------+------------------+\n",
            "|Basic Check|Warning    |Success     |containsURL(description)|Success          |                  |\n",
            "+-----------+-----------+------------+------------------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**containsEmail**(column, assertion=None, hint=None)--\n",
        "\n",
        "Verifies against a Email pattern\n"
      ],
      "metadata": {
        "id": "L5jTFwdpGvI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df4 = spark.createDataFrame([\n",
        " (1, \"The email address is foo@example.com\"),\n",
        " (2, \"Mail at bar@example.com\"),\n",
        " (3, None, ),\n",
        " (4, \"Just use this foobar@baz.com\")],\n",
        "['id', 'check_for_mail'])\n",
        "df4.show(truncate=False)"
      ],
      "metadata": {
        "id": "WSk3bdfaF8UD",
        "outputId": "f84f1cda-c180-48a6-afac-2bc9a46795e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------------------------------------+\n",
            "|id |check_for_mail                      |\n",
            "+---+------------------------------------+\n",
            "|1  |The email address is foo@example.com|\n",
            "|2  |Mail at bar@example.com             |\n",
            "|3  |null                                |\n",
            "|4  |Just use this foobar@baz.com        |\n",
            "+---+------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df4) \\\n",
        " .addCheck(check.containsEmail(\"check_for_mail\", lambda x: x >= 0.3))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "id": "l38SteXXGlYL",
        "outputId": "050d3a7f-3e7c-467b-e7cb-07a85eacc8e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+-----------------------------+-----------------+------------------+\n",
            "|check      |check_level|check_status|constraint                   |constraint_status|constraint_message|\n",
            "+-----------+-----------+------------+-----------------------------+-----------------+------------------+\n",
            "|Basic Check|Warning    |Success     |containsEmail(check_for_mail)|Success          |                  |\n",
            "+-----------+-----------+------------+-----------------------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df4.show(truncate=False)"
      ],
      "metadata": {
        "id": "HTxwCgIXGqse",
        "outputId": "4d66e902-ebc6-4a19-a8b6-55e12df18283",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------------------------------------+\n",
            "|id |check_for_mail                      |\n",
            "+---+------------------------------------+\n",
            "|1  |The email address is foo@example.com|\n",
            "|2  |Mail at bar@example.com             |\n",
            "|3  |null                                |\n",
            "|4  |Just use this foobar@baz.com        |\n",
            "+---+------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df4) \\\n",
        " .addCheck(check.containsEmail(\"check_for_mail\", lambda x: x <= 0.1))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "id": "a7P0Wd2xGW1T",
        "outputId": "7e377fe5-74ca-45c5-87ee-947d6118595e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+-----------------------------+-----------------+-----------------------------------------------------+\n",
            "|check      |check_level|check_status|constraint                   |constraint_status|constraint_message                                   |\n",
            "+-----------+-----------+------------+-----------------------------+-----------------+-----------------------------------------------------+\n",
            "|Basic Check|Warning    |Warning     |containsEmail(check_for_mail)|Failure          |Value: 0.75 does not meet the constraint requirement!|\n",
            "+-----------+-----------+------------+-----------------------------+-----------------+-----------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**hasPattern**(column, pattern, assertion=None, name=None, hint=None)\n",
        "--\n",
        "\n",
        "Matches the regex Pattern.\n"
      ],
      "metadata": {
        "id": "1e_dVwvwa9SA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "id": "sWCvk4o5Zyn7",
        "outputId": "86b394df-5ac4-4834-a96c-b662156fad29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+----+----+----+---+\n",
            "|  a|  b|   c|   d|   e|  f|\n",
            "+---+---+----+----+----+---+\n",
            "|foo|  1|   5|  10|null|  0|\n",
            "|bar|  2|   6|   4|  12| 90|\n",
            "|baz|  3|null|null|  20|-10|\n",
            "|cab|  3|   8|null|null| 50|\n",
            "+---+---+----+----+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df) \\\n",
        " .addCheck(check.hasPattern(\"a\",r\"f*\",lambda x:x>=0.5))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "id": "8NAchH-nZ08G",
        "outputId": "a84306f8-5eef-4a6f-d344-5d5352b78f99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+-----------------------------+-----------------+-----------------------------------------------------+\n",
            "|check      |check_level|check_status|constraint                   |constraint_status|constraint_message                                   |\n",
            "+-----------+-----------+------------+-----------------------------+-----------------+-----------------------------------------------------+\n",
            "|Basic Check|Warning    |Warning     |PatternMatchConstraint(a, f*)|Failure          |Value: 0.25 does not meet the constraint requirement!|\n",
            "+-----------+-----------+------------+-----------------------------+-----------------+-----------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**isGreaterThan**(columnA, columnB, assertion=None, hint=None)\n",
        "\n",
        "Asserts that, in each row, the value of columnA is greater than the value of columnB"
      ],
      "metadata": {
        "id": "Ap69UVT_7lj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df5 = spark.sparkContext.parallelize([\n",
        "    Row(a=\"foo\", b=1, c=5, d=10, e=None, f=100),\n",
        "    Row(a=\"bar\", b=2, c=6, d=4, e= 12, f=90),\n",
        "    Row(a=\"baz\", b=3, c=None, d=None, e = 20, f= 10),\n",
        "    Row(a=\"cab\", b=3, c=8,  d=None, e =None, f=50)]).toDF()\n",
        "df5.show()"
      ],
      "metadata": {
        "id": "9yI-l5046sOk",
        "outputId": "b33efeb6-4f1d-402f-cabc-ed43dfc0d91d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+----+----+----+---+\n",
            "|  a|  b|   c|   d|   e|  f|\n",
            "+---+---+----+----+----+---+\n",
            "|foo|  1|   5|  10|null|100|\n",
            "|bar|  2|   6|   4|  12| 90|\n",
            "|baz|  3|null|null|  20| 10|\n",
            "|cab|  3|   8|null|null| 50|\n",
            "+---+---+----+----+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df5) \\\n",
        " .addCheck(check.isGreaterThan(\"c\",\"b\"))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "id": "HGCPW0AE7BP0",
        "outputId": "286af423-1fbc-4db4-85db-102e0c2af9cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+--------------------------------------------------------------------------------+-----------------+-----------------------------------------------------+\n",
            "|check      |check_level|check_status|constraint                                                                      |constraint_status|constraint_message                                   |\n",
            "+-----------+-----------+------------+--------------------------------------------------------------------------------+-----------------+-----------------------------------------------------+\n",
            "|Basic Check|Warning    |Warning     |ComplianceConstraint(Compliance(c is greater than b,c > b,None,List(c, b),None))|Failure          |Value: 0.75 does not meet the constraint requirement!|\n",
            "+-----------+-----------+------------+--------------------------------------------------------------------------------+-----------------+-----------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**hasDataType**(column, datatype: ConstrainableDataTypes, assertion=None, hint=None)--\n",
        "\n",
        "Check to run against the fraction of rows that conform to the given data type"
      ],
      "metadata": {
        "id": "X-yOZDDFWLK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df5.show()"
      ],
      "metadata": {
        "id": "OJ2Ew2Y-U_JU",
        "outputId": "9a120286-3fb8-48d6-aba2-8f59acb6420e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+----+----+----+---+\n",
            "|  a|  b|   c|   d|   e|  f|\n",
            "+---+---+----+----+----+---+\n",
            "|foo|  1|   5|  10|null|100|\n",
            "|bar|  2|   6|   4|  12| 90|\n",
            "|baz|  3|null|null|  20| 10|\n",
            "|cab|  3|   8|null|null| 50|\n",
            "+---+---+----+----+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "check = Check(spark, CheckLevel.Warning, \"Basic Check\")\n",
        "checkResult = VerificationSuite(spark) \\\n",
        " .onData(df5) \\\n",
        " .addCheck(check.hasDataType(\"c\",ConstrainableDataTypes.Numeric))\\\n",
        " .run()\n",
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show(truncate=False)"
      ],
      "metadata": {
        "id": "MIj_bi2CU9jU",
        "outputId": "8b81316e-5921-4dce-d779-3d5375626cac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+------------+----------------------------------------------------------------------------+-----------------+------------------+\n",
            "|check      |check_level|check_status|constraint                                                                  |constraint_status|constraint_message|\n",
            "+-----------+-----------+------------+----------------------------------------------------------------------------+-----------------+------------------+\n",
            "|Basic Check|Warning    |Success     |AnalysisBasedConstraint(DataType(c,None),<function1>,Some(<function1>),None)|Success          |                  |\n",
            "+-----------+-----------+------------+----------------------------------------------------------------------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}